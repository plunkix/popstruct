import os
import shutil
import json
from typing import Dict, List, Optional
from datetime import datetime
import pandas as pd


class ReportService:
    """Service for generating analysis reports."""

    def __init__(self, output_dir: str):
        self.output_dir = output_dir
        os.makedirs(output_dir, exist_ok=True)

    def create_summary_report(
        self,
        job_info: Dict,
        dataset_info: Dict,
        results: Dict,
        output_path: str
    ) -> str:
        """
        Create a text summary report.

        Args:
            job_info: job metadata
            dataset_info: dataset metadata
            results: analysis results
            output_path: path to save report

        Returns:
            path to saved report
        """
        with open(output_path, "w") as f:
            f.write("=" * 80 + "\n")
            f.write("PopStruct Analysis Report\n")
            f.write("=" * 80 + "\n\n")

            # Job info
            f.write("JOB INFORMATION\n")
            f.write("-" * 80 + "\n")
            f.write(f"Job ID: {job_info.get('id')}\n")
            f.write(f"Job Name: {job_info.get('name')}\n")
            f.write(f"Analysis Type: {job_info.get('analysis_type')}\n")
            f.write(f"Date: {datetime.utcnow().strftime('%Y-%m-%d %H:%M:%S')} UTC\n")
            f.write("\n")

            # Dataset info
            f.write("DATASET INFORMATION\n")
            f.write("-" * 80 + "\n")
            f.write(f"Dataset Name: {dataset_info.get('name')}\n")
            f.write(f"File Type: {dataset_info.get('file_type')}\n")
            f.write(f"Number of Samples: {dataset_info.get('n_samples')}\n")
            f.write(f"Number of Variants: {dataset_info.get('n_variants')}\n")
            f.write("\n")

            # PCA results
            if "pca" in results:
                pca = results["pca"]
                f.write("PCA RESULTS\n")
                f.write("-" * 80 + "\n")
                f.write(f"Number of Components: {len(pca.get('variance_explained', []))}\n")
                f.write("\nVariance Explained by Each Component:\n")
                for i, var in enumerate(pca.get("variance_explained", []), 1):
                    f.write(f"  PC{i}: {var:.4f} ({var*100:.2f}%)\n")
                cumulative_var = sum(pca.get("variance_explained", [])[:3])
                f.write(f"\nCumulative variance (PC1-PC3): {cumulative_var:.4f} ({cumulative_var*100:.2f}%)\n")
                f.write("\n")

            # Clustering results
            if "clustering" in results:
                clustering = results["clustering"]
                f.write("CLUSTERING RESULTS\n")
                f.write("-" * 80 + "\n")
                f.write(f"Number of Clusters: {clustering.get('n_clusters')}\n")
                f.write(f"Silhouette Score: {clustering.get('silhouette_score', 0):.4f}\n")
                f.write("\n")

            # Kinship results
            if "kinship" in results:
                kinship = results["kinship"]
                f.write("KINSHIP ANALYSIS RESULTS\n")
                f.write("-" * 80 + "\n")
                f.write(f"Method: {kinship.get('method', 'IBS').upper()}\n")
                f.write(f"Matrix Size: {dataset_info.get('n_samples')} x {dataset_info.get('n_samples')}\n")
                f.write("\n")

            # File listing
            f.write("OUTPUT FILES\n")
            f.write("-" * 80 + "\n")
            for file_name in results.get("files", []):
                f.write(f"  - {file_name}\n")
            f.write("\n")

            f.write("=" * 80 + "\n")
            f.write("Report generated by PopStruct\n")
            f.write("=" * 80 + "\n")

        return output_path

    def create_json_metadata(
        self,
        job_info: Dict,
        dataset_info: Dict,
        results: Dict,
        output_path: str
    ) -> str:
        """
        Create JSON metadata file.

        Args:
            job_info: job metadata
            dataset_info: dataset metadata
            results: analysis results
            output_path: path to save JSON

        Returns:
            path to saved JSON
        """
        metadata = {
            "job": job_info,
            "dataset": dataset_info,
            "results": results,
            "generated_at": datetime.utcnow().isoformat()
        }

        with open(output_path, "w") as f:
            json.dump(metadata, f, indent=2)

        return output_path

    def package_results(self, job_dir: str, output_zip: str) -> str:
        """
        Package all results into a ZIP file.

        Args:
            job_dir: directory containing all result files
            output_zip: path to output ZIP file

        Returns:
            path to created ZIP file
        """
        # Remove .zip extension if present (shutil.make_archive adds it)
        output_base = output_zip.replace(".zip", "")

        # Create ZIP archive
        shutil.make_archive(output_base, "zip", job_dir)

        return output_base + ".zip"

    def generate_full_report(
        self,
        job_info: Dict,
        dataset_info: Dict,
        pca_results: Optional[Dict] = None,
        clustering_results: Optional[Dict] = None,
        kinship_results: Optional[Dict] = None
    ) -> Dict[str, str]:
        """
        Generate a complete analysis report with all files.

        Returns:
            Dictionary with paths to generated files
        """
        files = {}

        # Compile results
        results = {}
        result_files = []

        if pca_results:
            results["pca"] = pca_results
            if "components_path" in pca_results:
                result_files.append(os.path.basename(pca_results["components_path"]))
            if "plot_path" in pca_results:
                result_files.append(os.path.basename(pca_results["plot_path"]))
            if "scree_plot_path" in pca_results:
                result_files.append(os.path.basename(pca_results["scree_plot_path"]))

        if clustering_results:
            results["clustering"] = clustering_results
            if "labels_path" in clustering_results:
                result_files.append(os.path.basename(clustering_results["labels_path"]))
            if "plot_path" in clustering_results:
                result_files.append(os.path.basename(clustering_results["plot_path"]))

        if kinship_results:
            results["kinship"] = kinship_results
            if "matrix_path" in kinship_results:
                result_files.append(os.path.basename(kinship_results["matrix_path"]))
            if "heatmap_path" in kinship_results:
                result_files.append(os.path.basename(kinship_results["heatmap_path"]))

        results["files"] = result_files

        # Create summary report
        summary_path = os.path.join(self.output_dir, "report.txt")
        files["summary"] = self.create_summary_report(
            job_info, dataset_info, results, summary_path
        )

        # Create JSON metadata
        json_path = os.path.join(self.output_dir, "metadata.json")
        files["metadata"] = self.create_json_metadata(
            job_info, dataset_info, results, json_path
        )

        # Package everything
        zip_path = os.path.join(
            os.path.dirname(self.output_dir),
            f"job_{job_info['id']}_results.zip"
        )
        files["zip"] = self.package_results(self.output_dir, zip_path)

        return files
